#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
ì‹¤ì œ ì´ë¯¸ì§€ URLì„ ì–»ì–´ë³´ëŠ” ì˜ˆì‹œ
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import re

async def simple_scrape_test(url: str):
    """ê°„ë‹¨í•œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    try:
        async with aiohttp.ClientSession() as session:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            async with session.get(url, headers=headers, timeout=10) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # ì œëª© ì°¾ê¸°
                    title_selectors = ['h1', '.product-title', '[data-testid="product-title"]', 'title']
                    title = "Unknown"
                    for selector in title_selectors:
                        element = soup.select_one(selector)
                        if element:
                            title = element.get_text().strip()[:100]
                            break
                    
                    # ì´ë¯¸ì§€ ì°¾ê¸°
                    img_selectors = [
                        'img[src*="product"]', 
                        '.product-image img', 
                        'img[alt*="product"]',
                        'meta[property="og:image"]'
                    ]
                    image_url = None
                    for selector in img_selectors:
                        element = soup.select_one(selector)
                        if element:
                            image_url = element.get('src') or element.get('content')
                            if image_url and image_url.startswith('http'):
                                break
                    
                    # ê°€ê²© ì°¾ê¸° (ê°„ë‹¨í•œ íŒ¨í„´)
                    price_text = soup.get_text()
                    price_match = re.search(r'[\$â‚©](\d+(?:,\d{3})*(?:\.\d{2})?)', price_text)
                    price = price_match.group(1) if price_match else None
                    
                    return {
                        'url': url,
                        'title': title,
                        'image': image_url,
                        'price': price,
                        'success': True
                    }
                else:
                    return {
                        'url': url,
                        'error': f'HTTP {response.status}',
                        'success': False
                    }
    except Exception as e:
        return {
            'url': url,
            'error': str(e),
            'success': False
        }

async def test_real_sites():
    """ì‹¤ì œ ì‚¬ì´íŠ¸ë“¤ í…ŒìŠ¤íŠ¸"""
    test_urls = [
        "https://caffemuseo.co.kr/",
        "https://www.megacoffee.co.kr/",
        "https://www.amazon.com/dp/B08N5WRWNW",  # ì•„ë§ˆì¡´ ì˜ˆì‹œ
    ]
    
    print("ğŸ” ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    for url in test_urls:
        print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸: {url}")
        result = await simple_scrape_test(url)
        
        if result['success']:
            print(f"âœ… ì œëª©: {result['title']}")
            print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€: {result['image']}")
            print(f"ğŸ’° ê°€ê²©: {result['price']}")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result['error']}")

if __name__ == "__main__":
    asyncio.run(test_real_sites())