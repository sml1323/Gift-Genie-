# Gift Genie MCP íŒŒì´í”„ë¼ì¸ ë°ëª¨
# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ê¸°ë³¸ êµ¬ì¡° ì‹œì—°

import asyncio
import json
import hashlib
import time
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 1. ë°ì´í„° ëª¨ë¸
@dataclass
class PipelineMetrics:
    total_time: float
    ai_generation_time: float
    search_execution_time: float
    scraping_execution_time: float
    integration_time: float
    cache_hits: int = 0
    cache_misses: int = 0
    errors: List[str] = None

    def __post_init__(self):
        if self.errors is None:
            self.errors = []

@dataclass
class MCPResponse:
    request_id: str
    success: bool
    recommendations: List[Dict[str, Any]]
    search_insights: Dict[str, Any]
    metrics: PipelineMetrics
    errors: List[str]

# 2. ì‹œë®¬ë ˆì´ì…˜ í´ë¼ì´ì–¸íŠ¸ë“¤
class MockAIClient:
    """GPT-4o-mini ì‹œë®¬ë ˆì´ì…˜"""
    
    async def generate_search_strategy(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì „ëµ ìƒì„± ì‹œë®¬ë ˆì´ì…˜"""
        await asyncio.sleep(0.1)  # API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        
        recipient = request.get("recipient", {})
        interests = recipient.get("interests", [])
        
        return {
            "search_keywords": interests + ["ì„ ë¬¼", "ì¶”ì²œ"],
            "product_categories": ["ìƒí™œìš©í’ˆ", "ì „ìê¸°ê¸°", "íŒ¨ì…˜"],
            "trending_terms": ["ì¸ê¸°", "ë² ìŠ¤íŠ¸", "ì‹ ìƒ"],
            "exclusions": ["ì¤‘ê³ ", "ë¦¬í¼"]
        }
    
    async def generate_recommendations(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ìµœì¢… ì¶”ì²œ ìƒì„± ì‹œë®¬ë ˆì´ì…˜"""
        await asyncio.sleep(0.1)
        
        request = context["request"]
        budget = request.get("budget", {})
        max_price = budget.get("max", 100000)
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ì¶”ì²œ ê²°ê³¼
        recommendations = []
        for i in range(1, 4):  # 3ê°œ ì¶”ì²œ
            recommendations.append({
                "rank": i,
                "product_name": f"ì¶”ì²œ ìƒí’ˆ {i}",
                "brand": f"ë¸Œëœë“œ {i}",
                "price": min(max_price * 0.8, 50000 + i * 10000),
                "image_url": f"https://example.com/product{i}.jpg",
                "purchase_url": f"https://shop.example.com/product{i}",
                "recommendation_reason": f"ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ì™€ ì˜ˆì‚°ì„ ê³ ë ¤í•œ {i}ë²ˆì§¸ ì¶”ì²œì…ë‹ˆë‹¤.",
                "match_score": 90 - i * 5,
                "tags": ["ì¸ê¸°", "ì¶”ì²œ", f"íƒœê·¸{i}"]
            })
        
        return recommendations

class MockSearchClient:
    """Brave Search ì‹œë®¬ë ˆì´ì…˜"""
    
    async def search_products(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒí’ˆ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜"""
        await asyncio.sleep(0.2)
        
        keywords = strategy.get("search_keywords", [])
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ê²€ìƒ‰ ê²°ê³¼
        results = []
        for i, keyword in enumerate(keywords[:5]):
            results.append({
                "title": f"{keyword} ê´€ë ¨ ìƒí’ˆ {i+1}",
                "url": f"https://shop.example.com/{keyword}-product-{i+1}",
                "description": f"{keyword}ì— ëŒ€í•œ ìƒì„¸í•œ ìƒí’ˆ ì„¤ëª…ì…ë‹ˆë‹¤.",
                "domain": "example.com",
                "relevance_score": 0.9 - i * 0.1
            })
        
        return {
            "results": results,
            "total_count": len(results),
            "trending_insights": {
                "popular_domains": [("example.com", 5), ("shop.com", 3)],
                "trending_keywords": [(kw, i+1) for i, kw in enumerate(keywords)]
            }
        }

class MockScrapingClient:
    """Apify ìŠ¤í¬ë˜í•‘ ì‹œë®¬ë ˆì´ì…˜"""
    
    async def scrape_product_details(self, urls: List[str]) -> List[Dict[str, Any]]:
        """ìƒí’ˆ ìƒì„¸ì •ë³´ ìŠ¤í¬ë˜í•‘ ì‹œë®¬ë ˆì´ì…˜"""
        await asyncio.sleep(0.3)
        
        results = []
        for i, url in enumerate(urls[:5]):
            results.append({
                "url": url,
                "name": f"ìƒí’ˆëª… {i+1}",
                "brand": f"ë¸Œëœë“œ {i+1}",
                "price": 50000 + i * 10000,
                "original_price": 60000 + i * 12000,
                "discount_rate": 15 + i * 2,
                "image_urls": [f"https://example.com/image{i+1}.jpg"],
                "rating": 4.5 - i * 0.1,
                "review_count": 100 + i * 20,
                "description": f"ìƒí’ˆ {i+1}ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì…ë‹ˆë‹¤.",
                "availability": "in_stock",
                "vendor": ["ì¿ íŒ¡", "ì§€ë§ˆì¼“", "11ë²ˆê°€"][i % 3]
            })
        
        return results

# 3. ê°„ë‹¨í•œ ìºì‹œ ë§¤ë‹ˆì €
class MockCacheManager:
    """ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self):
        self.cache = {}
        self.hit_count = 0
        self.miss_count = 0
    
    def _generate_key(self, prefix: str, data: Any) -> str:
        data_str = json.dumps(data, sort_keys=True)
        hash_obj = hashlib.md5(data_str.encode())
        return f"{prefix}:{hash_obj.hexdigest()}"
    
    async def get(self, prefix: str, data: Any) -> Optional[Dict]:
        key = self._generate_key(prefix, data)
        if key in self.cache:
            self.hit_count += 1
            return self.cache[key]
        else:
            self.miss_count += 1
            return None
    
    async def set(self, prefix: str, data: Any, value: Dict, ttl: int):
        key = self._generate_key(prefix, data)
        self.cache[key] = value
        # TTLì€ ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” ë¬´ì‹œ

# 4. ë©”ì¸ íŒŒì´í”„ë¼ì¸
class MCPPipelineDemo:
    """MCP íŒŒì´í”„ë¼ì¸ ë°ëª¨"""
    
    def __init__(self):
        self.ai_client = MockAIClient()
        self.search_client = MockSearchClient()
        self.scraping_client = MockScrapingClient()
        self.cache_manager = MockCacheManager()
    
    async def process_request(self, request: Dict[str, Any]) -> MCPResponse:
        """ìš”ì²­ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        request_id = hashlib.md5(json.dumps(request, sort_keys=True).encode()).hexdigest()[:8]
        start_time = time.time()
        
        logger.info(f"[{request_id}] íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        try:
            # 1ë‹¨ê³„: AI ê²€ìƒ‰ ì „ëµ ìƒì„±
            logger.info(f"[{request_id}] 1ë‹¨ê³„: AI ê²€ìƒ‰ ì „ëµ ìƒì„±")
            stage_start = time.time()
            
            strategy = await self._ai_generation_stage(request)
            ai_time = time.time() - stage_start
            
            logger.info(f"[{request_id}] ê²€ìƒ‰ í‚¤ì›Œë“œ: {strategy['search_keywords']}")
            
            # 2ë‹¨ê³„: ê²€ìƒ‰ ì‹¤í–‰
            logger.info(f"[{request_id}] 2ë‹¨ê³„: Brave Search ê²€ìƒ‰")
            stage_start = time.time()
            
            search_results = await self._search_execution_stage(strategy)
            search_time = time.time() - stage_start
            
            logger.info(f"[{request_id}] ê²€ìƒ‰ ê²°ê³¼: {search_results['total_count']}ê°œ")
            
            # 3ë‹¨ê³„: ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
            logger.info(f"[{request_id}] 3ë‹¨ê³„: Apify ìŠ¤í¬ë˜í•‘")
            stage_start = time.time()
            
            urls = [result["url"] for result in search_results["results"]]
            product_details = await self._scraping_execution_stage(urls)
            scraping_time = time.time() - stage_start
            
            logger.info(f"[{request_id}] ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(product_details)}ê°œ")
            
            # 4ë‹¨ê³„: ê²°ê³¼ í†µí•©
            logger.info(f"[{request_id}] 4ë‹¨ê³„: ê²°ê³¼ í†µí•©")
            stage_start = time.time()
            
            context = {
                "request": request,
                "strategy": strategy,
                "search_results": search_results["results"],
                "product_details": product_details
            }
            
            recommendations = await self._integration_stage(context)
            integration_time = time.time() - stage_start
            
            total_time = time.time() - start_time
            
            # ë©”íŠ¸ë¦­ ìƒì„±
            metrics = PipelineMetrics(
                total_time=total_time,
                ai_generation_time=ai_time,
                search_execution_time=search_time,
                scraping_execution_time=scraping_time,
                integration_time=integration_time,
                cache_hits=self.cache_manager.hit_count,
                cache_misses=self.cache_manager.miss_count
            )
            
            logger.info(f"[{request_id}] íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ({total_time:.2f}ì´ˆ)")
            
            return MCPResponse(
                request_id=request_id,
                success=True,
                recommendations=recommendations,
                search_insights=search_results.get("trending_insights", {}),
                metrics=metrics,
                errors=[]
            )
            
        except Exception as e:
            logger.error(f"[{request_id}] íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            
            metrics = PipelineMetrics(
                total_time=time.time() - start_time,
                ai_generation_time=0,
                search_execution_time=0,
                scraping_execution_time=0,
                integration_time=0,
                errors=[str(e)]
            )
            
            return MCPResponse(
                request_id=request_id,
                success=False,
                recommendations=[],
                search_insights={},
                metrics=metrics,
                errors=[str(e)]
            )
    
    async def _ai_generation_stage(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """AI ìƒì„± ë‹¨ê³„"""
        cached = await self.cache_manager.get("ai", request)
        if cached:
            logger.info("AI ì „ëµ ìºì‹œ íˆíŠ¸")
            return cached
        
        strategy = await self.ai_client.generate_search_strategy(request)
        await self.cache_manager.set("ai", request, strategy, 1800)  # 30ë¶„
        
        return strategy
    
    async def _search_execution_stage(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰ ë‹¨ê³„"""
        cached = await self.cache_manager.get("search", strategy)
        if cached:
            logger.info("ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ íˆíŠ¸")
            return cached
        
        results = await self.search_client.search_products(strategy)
        await self.cache_manager.set("search", strategy, results, 3600)  # 1ì‹œê°„
        
        return results
    
    async def _scraping_execution_stage(self, urls: List[str]) -> List[Dict[str, Any]]:
        """ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ ë‹¨ê³„"""
        return await self.scraping_client.scrape_product_details(urls)
    
    async def _integration_stage(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê²°ê³¼ í†µí•© ë‹¨ê³„"""
        return await self.ai_client.generate_recommendations(context)

# 5. ë°ëª¨ ì‹¤í–‰
async def demo_main():
    """ë°ëª¨ ì‹¤í–‰"""
    print("ğŸ Gift Genie MCP íŒŒì´í”„ë¼ì¸ ë°ëª¨")
    print("=" * 50)
    
    pipeline = MCPPipelineDemo()
    
    # í…ŒìŠ¤íŠ¸ ìš”ì²­ 1
    test_request_1 = {
        "recipient": {
            "gender": "female",
            "age_group": "30s",
            "interests": ["reading", "coffee", "travel"]
        },
        "budget": {
            "min": 30000,
            "max": 100000
        },
        "occasion": "birthday"
    }
    
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ ìš”ì²­ 1:")
    print(f"- ë°›ëŠ” ì‚¬ëŒ: 30ëŒ€ ì—¬ì„±")
    print(f"- ê´€ì‹¬ì‚¬: {', '.join(test_request_1['recipient']['interests'])}")
    print(f"- ì˜ˆì‚°: {test_request_1['budget']['min']:,}ì› ~ {test_request_1['budget']['max']:,}ì›")
    print(f"- ëª©ì : {test_request_1['occasion']}")
    
    result_1 = await pipeline.process_request(test_request_1)
    
    print(f"\nâœ… ê²°ê³¼ 1:")
    print(f"- ìš”ì²­ ID: {result_1.request_id}")
    print(f"- ì„±ê³µ ì—¬ë¶€: {result_1.success}")
    print(f"- ì´ ì²˜ë¦¬ ì‹œê°„: {result_1.metrics.total_time:.2f}ì´ˆ")
    print(f"- ì¶”ì²œ ìƒí’ˆ ìˆ˜: {len(result_1.recommendations)}")
    print(f"- ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤: {result_1.metrics.cache_hits}/{result_1.metrics.cache_misses}")
    
    if result_1.recommendations:
        print("\nğŸ¯ ì¶”ì²œ ìƒí’ˆ:")
        for rec in result_1.recommendations:
            print(f"  {rec['rank']}. {rec['product_name']} ({rec['brand']})")
            print(f"     ê°€ê²©: {rec['price']:,}ì›, ë§¤ì¹­ì ìˆ˜: {rec['match_score']}")
            print(f"     ì´ìœ : {rec['recommendation_reason']}")
    
    # í…ŒìŠ¤íŠ¸ ìš”ì²­ 2 (ìºì‹œ í…ŒìŠ¤íŠ¸)
    print("\n" + "=" * 50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ ìš”ì²­ 2 (ë™ì¼ ìš”ì²­ìœ¼ë¡œ ìºì‹œ í…ŒìŠ¤íŠ¸):")
    
    result_2 = await pipeline.process_request(test_request_1)  # ê°™ì€ ìš”ì²­
    
    print(f"\nâœ… ê²°ê³¼ 2:")
    print(f"- ìš”ì²­ ID: {result_2.request_id}")
    print(f"- ì´ ì²˜ë¦¬ ì‹œê°„: {result_2.metrics.total_time:.2f}ì´ˆ (ìºì‹œë¡œ ë‹¨ì¶•)")
    print(f"- ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤: {result_2.metrics.cache_hits}/{result_2.metrics.cache_misses}")
    
    # ì„±ëŠ¥ ë¶„ì„
    print("\n" + "=" * 50)
    print("ğŸ“Š ì„±ëŠ¥ ë¶„ì„:")
    print(f"- ì²« ë²ˆì§¸ ìš”ì²­: {result_1.metrics.total_time:.2f}ì´ˆ")
    print(f"  â”” AI ìƒì„±: {result_1.metrics.ai_generation_time:.2f}ì´ˆ")
    print(f"  â”” ê²€ìƒ‰ ì‹¤í–‰: {result_1.metrics.search_execution_time:.2f}ì´ˆ") 
    print(f"  â”” ìŠ¤í¬ë˜í•‘: {result_1.metrics.scraping_execution_time:.2f}ì´ˆ")
    print(f"  â”” ê²°ê³¼ í†µí•©: {result_1.metrics.integration_time:.2f}ì´ˆ")
    
    print(f"- ë‘ ë²ˆì§¸ ìš”ì²­: {result_2.metrics.total_time:.2f}ì´ˆ (ìºì‹œ í™œìš©)")
    
    speed_improvement = (result_1.metrics.total_time - result_2.metrics.total_time) / result_1.metrics.total_time * 100
    print(f"- ìºì‹œë¡œ ì¸í•œ ì„±ëŠ¥ í–¥ìƒ: {speed_improvement:.1f}%")

if __name__ == "__main__":
    asyncio.run(demo_main())